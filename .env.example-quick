# .env - 빠른 시작용 최소 설정

# ===== 필수 설정 =====
# Git 설정 (코드 커밋용)
GIT_USER_NAME=Research Bot
GIT_USER_EMAIL=research.bot@localhost

# ===== 선택적 API 키 (나중에 추가 가능) =====
# IEEE Xplore API - https://developer.ieee.org/
# IEEE_API_KEY=

# CORE API - https://core.ac.uk/services/api
# CORE_API_KEY=

# Semantic Scholar - https://www.semanticscholar.org/product/api
# SEMANTIC_SCHOLAR_API_KEY=

# ===== 모델 설정 =====
# 8GB GPU용 추천 설정 (Mixtral 8x7B 양자화 버전)
OLLAMA_MODEL=mixtral:8x7b-instruct-v0.1-q4_K_M

# 메모리가 부족한 경우 다음 중 하나 선택:
# OLLAMA_MODEL=llama2:7b-chat-q4_K_M          # 4GB GPU
# OLLAMA_MODEL=mistral:7b-instruct-q4_K_M     # 6GB GPU
# OLLAMA_MODEL=phi-2:2.7b-chat-q4_K_M         # 2GB GPU (성능 제한)

# ===== 서비스 포트 (기본값) =====
MCP_PORT=3000
CRAWLER_PORT=5000
CODE_DEV_PORT=8080
DOC_GEN_PORT=5001

# ===== 기타 설정 (변경 불필요) =====
CLIENT_URL=http://localhost:3001
REDIS_HOST=redis
REDIS_PORT=6379
WORKSPACE_PATH=./workspace
DOCUMENTS_PATH=./documents
LOGS_PATH=./logs

# ===== 고급 설정 (선택사항) =====
# 최대 동시 크롤링 수
MAX_CONCURRENT_CRAWLS=3

# 연구 논문 최대 개수
MAX_PAPERS_PER_SEARCH=20

# 캐시 유효 시간 (초)
CACHE_TTL=3600

# 개발 모드 (더 자세한 로그)
NODE_ENV=development

# GPU 메모리 제한 (MB)
OLLAMA_GPU_MEMORY=7168  # 7GB for 8GB GPU