# docker-compose.yml (최적화 버전)
version: "3.8"

services:
    # Ollama LLM Engine (사전 빌드된 이미지 사용)
    ollama:
        image: ollama/ollama:latest
        container_name: research-ollama
        volumes:
            - ollama_models:/root/.ollama
            - ./models:/models
        environment:
            - OLLAMA_MODELS=/models
            - OLLAMA_HOST=0.0.0.0
        ports:
            - "11434:11434"
        networks:
            - research_net
        restart: unless-stopped
        healthcheck:
            test: ["CMD", "curl", "-f", "http://localhost:11434/"]
            interval: 30s
            timeout: 10s
            retries: 3

    # Redis Cache (사전 빌드된 이미지 사용)
    redis:
        image: redis:7-alpine
        container_name: research-redis
        command: redis-server --maxmemory 1gb --maxmemory-policy allkeys-lru
        volumes:
            - redis_data:/data
        ports:
            - "6379:6379"
        networks:
            - research_net
        restart: unless-stopped
        healthcheck:
            test: ["CMD", "redis-cli", "ping"]
            interval: 10s
            timeout: 5s
            retries: 3

    # MCP Server (빌드 캐싱 활용)
    mcp-server:
        build:
            context: ./mcp-server
            dockerfile: Dockerfile
            cache_from:
                - node:18-alpine
        image: research-mcp-server:latest
        container_name: research-mcp-server
        environment:
            - NODE_ENV=development
            - PORT=3000
            - REDIS_HOST=redis
            - REDIS_PORT=6379
            - OLLAMA_HOST=ollama
            - OLLAMA_PORT=11434
            - OLLAMA_MODEL=${OLLAMA_MODEL:-mixtral:8x7b-instruct-v0.1-q4_K_M}
            - CLIENT_URL=http://localhost:3000
            - CODE_DEV_HOST=code-developer
            - CODE_DEV_PORT=8080
            - DOC_GEN_HOST=doc-generator
            - DOC_GEN_PORT=5001
            - CRAWLER_HOST=research-crawler
            - CRAWLER_PORT=5000
        volumes:
            - ./workspace:/workspace
            - ./logs:/logs
        ports:
            - "3000:3000"
        networks:
            - research_net
        depends_on:
            redis:
                condition: service_healthy
            ollama:
                condition: service_healthy
        restart: unless-stopped

    # Research Crawler (빌드 캐싱 활용)
    research-crawler:
        build:
            context: ./research-crawler
            dockerfile: Dockerfile
            cache_from:
                - python:3.11-slim
        image: research-crawler:latest
        container_name: research-crawler
        environment:
            - REDIS_HOST=redis
            - REDIS_PORT=6379
            - SCHOLAR_API_KEY=${SCHOLAR_API_KEY}
            - IEEE_API_KEY=${IEEE_API_KEY}
            - PORT=5000
        volumes:
            - ./research_data:/data
            - crawler_cache:/cache
        ports:
            - "5000:5000"
        networks:
            - research_net
        depends_on:
            redis:
                condition: service_healthy
        restart: unless-stopped

    # Code Developer (빌드 캐싱 활용)
    code-developer:
        build:
            context: ./code-developer
            dockerfile: Dockerfile
            cache_from:
                - node:18-alpine
        image: code-developer:latest
        container_name: code-developer
        environment:
            - REDIS_HOST=redis
            - REDIS_PORT=6379
            - OLLAMA_HOST=ollama
            - OLLAMA_PORT=11434
            - GIT_USER_NAME=${GIT_USER_NAME:-Research Bot}
            - GIT_USER_EMAIL=${GIT_USER_EMAIL:-bot@research.local}
            - WORKSPACE_PATH=/workspace
            - PORT=8080
        volumes:
            - ./workspace:/workspace
            - ./git_repos:/repos
            - /var/run/docker.sock:/var/run/docker.sock:ro
        ports:
            - "8080:8080"
        networks:
            - research_net
        depends_on:
            redis:
                condition: service_healthy
            ollama:
                condition: service_healthy
        restart: unless-stopped

    # Document Generator (빌드 캐싱 활용)
    doc-generator:
        build:
            context: ./doc-generator
            dockerfile: Dockerfile
            cache_from:
                - python:3.11
        image: doc-generator:latest
        container_name: doc-generator
        environment:
            - REDIS_HOST=redis
            - REDIS_PORT=6379
            - OLLAMA_HOST=ollama
            - OLLAMA_PORT=11434
            - PORT=5001
        volumes:
            - ./workspace:/workspace
            - ./documents:/output
            - ./templates:/templates
        ports:
            - "5001:5001"
        networks:
            - research_net
        depends_on:
            redis:
                condition: service_healthy
            ollama:
                condition: service_healthy
        restart: unless-stopped

networks:
    research_net:
        driver: bridge

volumes:
    ollama_models:
        driver: local
    redis_data:
        driver: local
    crawler_cache:
        driver: local
